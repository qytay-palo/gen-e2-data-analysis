# User Story 3: Multi-Dimensional Data Preparation and Standardization

**As a** data analyst,  
**I want** to clean, standardize, and validate multi-dimensional healthcare system data,  
**so that** I can ensure data quality and consistency across all sustainability dimensions for reliable trend analysis.

## 1. ðŸŽ¯ Acceptance Criteria

- All numeric fields validated for accuracy (no negative values, outliers investigated)
- Temporal consistency validated (no retroactive changes, monotonic trends where expected)
- Categorical variables standardized (sector names, professional categories, disease classifications)
- Data transformations applied and documented (e.g., per-capita calculations, inflation adjustment)
- Outlier detection performed with flagging system (retain outliers but mark for investigation)
- Data quality scorecard updated with cleaning results
- Standardized datasets saved to `data/4_processed/` ready for analysis
- Comprehensive data cleaning report documenting all transformations and decisions
- Unit tests created for critical data validation rules

## 2. ðŸ”’ Technical Constraints

- **Data Processing**: Use Polars for efficient data cleaning and transformations
- **Validation Rules**: Document all validation logic explicitly
- **Reproducibility**: All transformations scripted and version-controlled
- **Outlier Detection**: Â±3 standard deviations for statistical outliers; domain-informed thresholds
- **Output Format**: Parquet format with schema validation
- **Audit Trail**: Log all data modifications with before/after comparisons

## 3. ðŸ“š Domain Knowledge References

- [Healthcare System Sustainability Metrics: Standard Metrics](../../../domain_knowledge/healthcare-system-sustainability-metrics.md#standard-metrics-and-kpis) - Valid ranges and thresholds
- [Healthcare Workforce Planning: Feature Engineering](../../../domain_knowledge/healthcare-workforce-planning.md#feature-engineering-guidance) - Workforce-specific validation rules
- [Disease Burden and Mortality Analysis](../../../domain_knowledge/disease-burden-mortality-analysis.md) - Mortality rate validation
- [Data Analysis Best Practices](.github/instructions/data-analysis-best-practices.instructions.md) - Data quality standards

## 4. ðŸ“¦ Dependencies

**External Packages:**
- **polars**: Data cleaning and transformations
- **numpy**: Statistical calculations for outlier detection
- **scipy**: Statistical tests for anomaly detection
- **loguru**: Cleaning operation logging

**Internal Dependencies:**
- Depends on: Story 2 (Data Integration & Temporal Alignment) - integrated datasets
- Input from: `data/3_interim/integrated_sustainability_data_2006_2018.parquet`
- Reuse: `src/utils/logger.py`, `src/data_processing/data_profiler.py`

## 5. âœ… Implementation Tasks

### Workforce Dimension Cleaning
- â¬œ Validate workforce counts: non-negative, reasonable ranges
  - Doctors: 8,000-20,000 (Singapore context)
  - Nurses: 15,000-45,000
  - Pharmacists: 1,500-4,000
- â¬œ Validate workforce growth: year-over-year change within -5% to +10%
- â¬œ Detect outliers: sudden spikes or drops requiring investigation
- â¬œ Standardize professional categories: consistent naming across years
- â¬œ Handle missing values: document any gaps in 2006-2018 window
- â¬œ Apply sector standardization: Public, Private, Not-for-Profit
- â¬œ Calculate total workforce: sum across professions for trend tracking

### Capacity Dimension Cleaning
- â¬œ Validate bed counts: non-negative, reasonable ranges
  - Total hospital beds: 10,000-15,000 (Singapore context)
  - Facility counts: positive integers
- â¬œ Validate capacity growth: year-over-year change within -2% to +8%
- â¬œ Detect anomalies: sudden capacity changes (facility closures/openings)
- â¬œ Standardize facility types: consistent categorization
- â¬œ Handle 2006-2008 data: apply back-fill or flag as reconstructed
- â¬œ Cross-validate: beds per facility ratio should be reasonable (200-500 beds per hospital)

### Utilization Dimension Cleaning
- â¬œ Validate admission counts: non-negative, reasonable ranges
- â¬œ Calculate admission rates: admissions per 1,000 population (require population data)
- â¬œ Validate demographic consistency: age groups sum to total, gender distribution reasonable
- â¬œ Detect seasonal anomalies: year-over-year trends should be smooth
- â¬œ Standardize age groups: consistent categorization across years
- â¬œ Handle missing demographic segments: document and flag

### Expenditure Dimension Cleaning
- â¬œ Validate expenditure amounts: non-negative, reasonable ranges
  - Total government health expenditure: SGD 8-15 billion (2006-2018)
- â¬œ Adjust for inflation: convert to constant 2018 SGD for trend analysis
  - Source inflation adjustment factors (Singapore CPI)
  - Apply to all years to enable real growth analysis
  - Document inflation methodology
- â¬œ Validate expenditure growth: real growth within 0% to +8% annually
- â¬œ Detect anomalies: sudden spending spikes or cuts
- â¬œ Standardize spending categories: consistent classification
- â¬œ Calculate per-capita expenditure: require population data

### Mortality Dimension Cleaning
- â¬œ Validate death rates: non-negative, age-standardized rates reasonable
  - All-cause mortality: 400-600 per 100,000 (typical range)
  - Disease-specific rates: validate against WHO benchmarks
- â¬œ Validate temporal consistency: death rates should trend gradually
- â¬œ Detect anomalies: sudden mortality spikes requiring investigation
- â¬œ Standardize disease categories: align with ICD classification
- â¬œ Handle missing disease categories: document incomplete coverage
- â¬œ Calculate leading causes: rank diseases by mortality burden

### Cross-Dimensional Validation
- â¬œ Validate workforce-capacity alignment:
  - Workforce-to-bed ratio: 1.5-2.5 FTE per bed
  - Flag if ratio outside expected range
- â¬œ Validate utilization-capacity alignment:
  - Bed utilization rate: 70-85% optimal
  - Admissions per bed: should be consistent over time
- â¬œ Validate expenditure-workforce alignment:
  - Expenditure per healthcare worker: should grow moderately
  - Flag if spending grows without workforce expansion
- â¬œ Validate mortality-utilization relationships:
  - High mortality diseases should correlate with admission patterns
- â¬œ Document cross-dimensional anomalies for investigation

### Outlier Detection and Flagging
- â¬œ Calculate z-scores for key metrics:
  - Workforce growth rates
  - Capacity expansion rates
  - Expenditure growth rates
  - Admission rate changes
  - Mortality rate changes
- â¬œ Flag statistical outliers: |z-score| > 3
- â¬œ Apply domain-informed thresholds:
  - Workforce growth >10% per year (flag for policy change investigation)
  - Capacity growth >8% per year (flag for facility expansion context)
  - Expenditure growth >10% real (flag for budget policy change)
- â¬œ Create outlier summary report: year, dimension, metric, value, z-score, flag
- â¬œ Retain outliers in dataset but add outlier flag field

### Data Transformation and Feature Creation
- â¬œ Calculate growth rates: year-over-year % change for all key metrics
- â¬œ Calculate indexed values: base year 2006 = 100 for trend visualization
- â¬œ Calculate per-capita metrics: workforce per capita, expenditure per capita (require population)
- â¬œ Calculate ratios: workforce-to-bed, expenditure-to-workforce, admissions-per-bed
- â¬œ Create temporal features: year index, decade indicator, pre/post-policy periods
- â¬œ Standardize units: ensure consistency (e.g., all financial in SGD millions)

### Population Data Integration (If Available)
- â¬œ Source Singapore population data 2006-2018 (Department of Statistics or external source)
- â¬œ Validate population data: reasonable growth rates (1-2% annually)
- â¬œ Integrate population data: join on year
- â¬œ Calculate per-capita metrics: workforce density, expenditure per capita, admission rates
- â¬œ Document population data source and any assumptions
- â¬œ If unavailable: flag per-capita calculations as future enhancement

### Data Quality Validation and Testing
- â¬œ Create validation test suite:
  - Test: All years 2006-2018 present
  - Test: No negative values in count/amount fields
  - Test: Sector values in allowed set
  - Test: Growth rates within expected ranges
  - Test: Cross-dimensional ratios reasonable
- â¬œ Run validation tests on cleaned data
- â¬œ Document test results: pass/fail status, issues identified
- â¬œ Update data quality scorecard with cleaning impact

### Output and Documentation
- â¬œ Save cleaned multi-dimensional dataset:
  - `data/4_processed/sustainability_data_cleaned_2006_2018.parquet`
- â¬œ Save dimension-specific cleaned datasets:
  - `data/4_processed/workforce_cleaned.parquet`
  - `data/4_processed/capacity_cleaned.parquet`
  - `data/4_processed/utilization_cleaned.parquet`
  - `data/4_processed/expenditure_cleaned.parquet`
  - `data/4_processed/mortality_cleaned.parquet`
- â¬œ Generate comprehensive data cleaning report documenting:
  - Validation rules applied
  - Outliers detected and flagged
  - Transformations applied (inflation adjustment, per-capita calculations)
  - Data quality before/after cleaning comparison
  - Recommendations for data interpretation
- â¬œ Create data dictionary for cleaned dataset:
  - Field names, types, descriptions
  - Calculated fields and formulas
  - Outlier flags and interpretation
- â¬œ Save cleaning log to `logs/etl/data_cleaning_{timestamp}.log`
- â¬œ Create unit test file: `tests/data/test_sustainability_data_quality.py`

## 6. Notes

**Inflation Adjustment Importance**: Healthcare expenditure must be adjusted for inflation to distinguish real growth from nominal growth. Use Singapore Consumer Price Index (CPI) for adjustment.

**Population Data Requirement**: Per-capita metrics are critical for sustainability analysis but require external population data. If unavailable in dataset, source from Singapore Department of Statistics.

**Outlier Retention Rationale**: Outliers may represent real policy changes (e.g., medical school intake expansion, new hospital opening). Retain but flag for contextual investigation rather than removing.

**Cross-Dimensional Validation Complexity**: Multi-dimensional cleaning requires understanding expected relationships (e.g., workforce should grow with capacity expansion). Domain knowledge essential for validation rules.

**Related Stories**: 
- Depends on: Story 2 (Data Integration)
- Enables: Story 4 (Exploratory Analysis), Story 5 (Feature Engineering)

**Estimated Effort**: 1 sprint (includes validation, cleaning, testing)
